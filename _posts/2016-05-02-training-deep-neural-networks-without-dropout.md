---
layout: post
title: Training Deep Neural Networks With Dropout
date: 2016-05-02
categories: [computer science]
tags: [machine learning]

---

# Training Deep Neural Networks With Dropout

In this episode, we discuss the bane of many machine learning algorithms - overfitting. It is also explained why it is an undesirable way to learn and how to combat it via dropout.

The paper "Dropout: A Simple Way to Prevent Neural Networks from
Overtting" is available here:
[https://www.cs.toronto.edu/~hinton/ab...](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)

Andrej Karpathy's autoencoder is available here:
[http://cs.stanford.edu/people/karpath...](http://cs.stanford.edu/people/karpathy/convnetjs/demo/autoencoder.html)

<iframe width="600" height="400" src="https://www.youtube.com/embed/LhhEv1dMpKE" frameborder="0" allowfullscreen></iframe>
