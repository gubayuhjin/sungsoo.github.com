---
layout: post
title: Universal Neural Style Transfer
date: 2017-12-16
categories: [computer science]
tags: [machine learning]

---


## Article Source
* Title: [Universal Neural Style Transfer](https://www.youtube.com/watch?v=v1oWke0Qf1E)

---

## Universal Neural Style Transfer

The paper "Universal Style Transfer via Feature Transforms" and its source code is available here:

[https://arxiv.org/abs/1705.08086](https://arxiv.org/abs/1705.08086) 

### Abstract

*Universal style transfer* aims to transfer arbitrary visual styles to content images. Existing *feed-forward* based methods, while enjoying the inference efficiency, are mainly limited by inability of generalizing to unseen styles or compromised visual quality. In this paper, we present a simple yet effective method that tackles these limitations without training on any pre-defined styles. The key ingredient of our method is a pair of feature transforms, whitening and coloring, that are embedded to an image reconstruction network. The whitening and coloring transforms reflect a direct matching of feature covariance of the content image to a given style image, which shares similar spirits with the optimization of Gram matrix based cost in neural style transfer. We demonstrate the effectiveness of our algorithm by generating high-quality stylized images with comparisons to a number of recent methods. We also analyze our method by visualizing the whitened features and synthesizing textures via simple feature coloring.

[https://github.com/Yijunmaverick/UniversalStyleTransfer](https://github.com/Yijunmaverick/UniversalStyleTransfer)


<iframe width="600" height="400" src="https://www.youtube.com/embed/v1oWke0Qf1E" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen></iframe>