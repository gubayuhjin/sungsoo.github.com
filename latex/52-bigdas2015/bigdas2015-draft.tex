% This is "sig-alternate.tex" V2.1 April 2013
% This file should be compiled with V2.5 of "sig-alternate.cls" May 2012
%
% This example file demonstrates the use of the 'sig-alternate.cls'
% V2.5 LaTeX2e document class file. It is for those submitting
% articles to ACM Conference Proceedings WHO DO NOT WISH TO
% STRICTLY ADHERE TO THE SIGS (PUBS-BOARD-ENDORSED) STYLE.
% The 'sig-alternate.cls' file will produce a similar-looking,
% albeit, 'tighter' paper resulting in, invariably, fewer pages.
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V2.5) produces:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% as against the acm_proc_article-sp.cls file which
% DOES NOT produce 1) thru' 3) above.
%
% Using 'sig-alternate.cls' you have control, however, from within
% the source .tex file, over both the CopyrightYear
% (defaulted to 200X) and the ACM Copyright Data
% (defaulted to X-XXXXX-XX-X/XX/XX).
% e.g.
% \CopyrightYear{2007} will cause 2007 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% ================= IF YOU HAVE QUESTIONS =======================
% Questions regarding the SIGS styles, SIGS policies and
% procedures, Conferences etc. should be sent to
% Adrienne Griscti (griscti@acm.org)
%
% Technical questions _only_ to
% Gerald Murray (murray@hq.acm.org)
% ===============================================================
%
% For tracking purposes - this is V2.0 - May 2012

\documentclass{sig-alternate-05-2015}

%%%%%%%%%%%%%%%%%%%%%%%%%
%                              My Commands
\newcommand{\bi}{\begin{itemize}}
\newcommand{\ei}{\end{itemize}}
\newcommand{\be}{\begin{enumerate}}
\newcommand{\ee}{\end{enumerate}}
\newcommand{\ii}{\item}
\newtheorem{Def}{Definition}
\newtheorem{Lem}{Lemma}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}

\usepackage{graphicx}
\graphicspath{%
        {converted_graphics/}
        {./images/}
}
\usepackage{times}

% 				End of My Commands
%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

% Copyright
\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
\doi{10.475/123_4}

% ISBN
%\isbn{123-4567-24-567/08/06}

%Conference
%\conferenceinfo{PLDI '13}{June 16--19, 2013, Seattle, WA, USA}

\acmPrice{\$15.00}

%
% --- Author Metadata here ---
\conferenceinfo{BIGDAS 2015}{Jeju Island, Republic of Korea}
%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{Flying KIWI: Design of Approximate Query Processing Engine for Interactive Data Analytics at Scale }

\numberofauthors{1} 

\author{
% 1st. author
\alignauthor
Sung-Soo Kim, Moonyoung Chung, Taewhi Lee and Jongho Won \\
       \affaddr{Electronics and Telecommunications Research Institute (ETRI)}\\
       \affaddr{218 Gajeong-ro, Yuseong-gu, Daejeon}\\
       \affaddr{South Korea}\\
       \email{\{sungsoo, mchung, taewhi, jhwon\}@etri.re.kr}
}

% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
\additionalauthors{Additional authors: John Smith (The Th{\o}rv{\"a}ld Group,
email: {\texttt{jsmith@affiliation.org}}) and Julius P.~Kumquat
(The Kumquat Consortium, email: {\texttt{jpkumquat@consortium.net}}).}
\date{30 July 1999}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
We present a architecture of approximate query processing engine for interactive big data analytics. 
In this paper, we summarize the design, development, and current state of deployment of the next generation of SQL-on-Hadoop system: KIWI.
\end{abstract}


\ccsdesc[500]{Information systems~Data management systems}
%\ccsdesc[300]{Data management systems~Query optimization}
\ccsdesc[200]{Data management systems engines~Parallel and distributed DBMSs}
\ccsdesc[100]{Parallel and distributed DBMSs~Relational parallel and distributed DBMSs}


%
% End generated code
%

%
%  Use this command to print the description
%
\printccsdesc

% We no longer use \terms command
%\terms{Theory}

\keywords{Approximate Query Processing; Big Data Analytics; Random Sampling}

\section{Introduction}
SQL-on-Hadoop is a class of analytical application tools that combine established SQL-style querying with Hadoop data framework.
One of the earliest efforts to combine SQL and Hadoop resulted in the Hive data warehouse, which featured HiveQL software for translating SQL-like queries into MapReduce jobs. Other tools that help support SQL-on-Hadoop include BigSQL, Drill, Hadapt, Hawq, H-SQL, Impala, Presto, SparkSQL, Tajo, Impala, Stinger, and Hive on Tez \cite{Babcock:2003, Chaudhuri:2007, Zeng:2015, Floratou:2014, Agarwal:2014, Agarwal:2013}.

When considering SQL-on-Hadoop, the most fundamental question is: What is the right tool for the job? For \textit{interactive queries} that require a few seconds (or even milliseconds) of response time, MapReduce (MR) is the wrong choice. On the other hand, for queries that require massive scale and runtime fault tolerance, an MR framework works well. MR was built for large-scale processing on big data, viewed mostly as \textit{batch processing}.
To provide an effective environment for big data analysis, we believe that processing systems will need to support both SQL and complex analytics efficiently, and to provide fine-grained fault recovery across both types of operations.

\textit{KIWI} is a  SQL-on-Hadoop system, which runs on hundreds of machines in existing Hadoop cluster.
It is decoupled from the underlying storage engine, unlike traditional database management systems where the query processing and the underlying storage engine are components of a single tightly-coupled system.
The ultimate goal of our work is to provide a SQL-on-Hadoop system, which can support interactive analytics as well as deep (batch) analytics. \textit{Flying KIWI} is an \textit{approximate} query processing engine in order to support interactive analytics.

\noindent
\textbf{Main contributions:} We present a novel system architecture for approximate query processing engine for interactive big data analytics. The contributions of our work can be summarized as follows.
\bi
\ii \textit{Dual-Mode}: 
Our proposed 
\ii \textit{Performance}: 
We introduce the 
\ei


\section{System Architecture}
This section focuses on the overall architecture for approximate query processing engine and describes each module in the system architecture. Figure \ref{fig:architecture} shows the architecture of our system
\begin{figure}[htb]
        \centering
        \includegraphics[width=0.48\textwidth]{architecture.pdf}
        \caption{System Architecture.}
        \label{fig:architecture}
\end{figure}

\noindent
\textbf{Closed Form Module:} 

\noindent
\textbf{Analytical Bootstrap Module:} 

\subsection{Sample Construction}
Sampling refers to the commonly used technique of evaluating the queries from a small random sample of the original database. The quality of the obtained approximate query answers plays an important role to their utility.

Given a table $T$ with $c$ columns $C_1, ..., C_c$ and $r$ rows, let $S=\{C_i, C_{i+1}, ..., C_{i+k}\}, i \leq i, i+k \leq c$, denote a column set that consists of $k$ columns in $T$. A query $q$ often need to scan fully or partially all data items in a column set $S_q$ of $T$. If data items in $S_q$ have been materialized (stored in a separate area from $T$ independently), for $q$, need to scan only materialized items instead of full table $T$. Because the number of columns in $S_q$ is often much smaller than $c$, scanning would be done much faster.

\begin{figure}[htb]
        \centering
        \includegraphics[width=0.3\textwidth]{columnset.pdf}
        \caption{Query Column Set.}
        \label{fig:qcs}
\end{figure}

Let $\xi(T, S)$ be the memory space needed to store all data items in a column set $S$ of a table $T$.
Let $\varphi$ be the storage system's space limit for materialized column sets.
Let $\omega$ be possible column sets of table $T$. 

$\sum_{\forall S_i \in \omega} \xi(T, S)$

\begin{figure}[htb]
        \centering
        \includegraphics[width=0.48\textwidth]{workflow.pdf}
        \caption{Approximate Query Processing Workflow.}
        \label{fig:workflow}
\end{figure}

\subsection{Sample Selection}
Online aggregation (OLA) is an attractive technique to respond aggregation queries by computing approximate answers with the error bars over time.
\section{Experiments}

\section{Related Work}


\section{Conclusion}



















































\small{
\bibliographystyle{abbrv}
\bibliography{sqlonhadoop}
}

\end{document}
