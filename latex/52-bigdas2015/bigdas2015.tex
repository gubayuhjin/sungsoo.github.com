
%%%%%%%%%%%%%%%%%%%%%%% file typeinst.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is the LaTeX source for the instructions to authors using
% the LaTeX document class 'llncs.cls' for contributions to
% the Lecture Notes in Computer Sciences series.
% http://www.springer.com/lncs       Springer Heidelberg 2006/05/04
%
% It may be used as a template for your own input copy it
% to a new file with a new name and use it as the basis
% for your article.
%
% NB: the document class 'llncs' has its own and detailed documentation, see
% ftp://ftp.springer.de/data/pubftp/pub/tex/latex/llncs/latex2e/llncsdoc.pdf
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass[runningheads,a4paper]{llncs}

\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx}

\usepackage{url}

\begin{document}

\mainmatter  % start of an individual contribution

% first the title is needed
\title{Big Data Platform}

% a short form should be given in case it is too long for the running head
\titlerunning{Big Data Platform}

% the name(s) of the author(s) follow(s) next
%
% NB: Chinese authors should write their first names(s) in front of
% their surnames. This ensures that the names appear correctly in
% the running heads and the author index.
%
\author{
Sung-Soo Kim, Jongho Won
}

%
%\authorrunning{Lecture Notes in Computer Science: Authors' Instructions}
% (feature abused for this document to repeat the title also on left hand pages)

% the affiliations are given next; don't give your e-mail address
% unless you accept that it will be published
\institute{ETRI\\
218 Gajeong-ro, Yuseong-gu, Deajeon, South Korea\\
\url{{sungsoo, jhwon}@etri.re.kr}\\
\url{http://www.etri.re.kr}}

%
% NB: a more complex sample for affiliations and the mapping to the
% corresponding authors can be found in the file "llncs.dem"
% (search for the string "\mainmatter" where a contribution starts).
% "llncs.dem" accompanies the document class "llncs.cls".
%

\toctitle{Lecture Notes in Computer Science}
\tocauthor{Authors' Instructions}
\maketitle


\begin{abstract}
Recent advances of software defined networking and optical switching technology make it possible to program the network stack all the way from physical topology to flow level traffic control. In this paper, we leverage the combination of SDN controller with optical switching to explore the tight integration of application and network control. We particularly study the run-time network configuration for big data applications to jointly optimize application performance and network utilization. We use Hadoop as an example to discuss the integrated network control architecture, job scheduling, topology and routing configuration mechanisms for Hadoop jobs. Our analysis suggests that such an integrated control has great potential to improve application performance with relatively small configuration overhead. We believe our study shows early promise of achieving the long-term goal of tight network and application integration using SDN.
\keywords{We would like to encourage you to list your keywords within
the abstract section}
\end{abstract}


\section{Introduction}
Network engineers and researchers have long sought effective ways to make networks more “application-aware”. A variety of methods for optimizing the network to improve application performance or availability have been considered. Some of these approaches have been edge-based, for example tuning protocol parameters at end-hosts to improve throughput [28], or choosing overlay nodes to direct traffic over application-optimized paths [23]. Examples of network-centric approaches include providing custom instances of routing protocols to applications [10], or even allowing applications to embed code in network devices to perform application processing [24].

While these earlier efforts have met with varying degrees of success and adoption, the recent emergence of the software-defined networking paradigm has created renewed interest in tailoring the network to better meet the needs of applications. By providing a well-defined programming interface to the network (e.g., OpenFlow), SDN provides an opportunity for more dynamic and flexible interaction with the network. Despite this promising vision, the ability of SDN to effectively configure or optimize the network to improve application performance and availability is still nascent.Recently, two concomitant trends in data center applications and network architecture present a new opportunity to leverage the capabilities of SDN for truly application-aware networking. The first is the growing prominence of big data applications which are used to extract value and insights efficiently from very large volumes of data [1, 2, 20, 29]. Many of these applications process data according to well-defined computation patterns, and also have a centralized management structure which makes it possible to leverage application-level information to optimize the network. The second trend is the growing number of proposals for data center network architectures that leverage optical switches to provide significantly increased point-to-point bandwidth with low cabling complexity and energy consumption [26, 18, 15, 25]. Some of this work has demonstrated how to collect network-level traffic data and intelligently allocate optical circuits between endpoints (e.g., top-of-rack switches) to improve application performance. But without a true application-level view of traffic demands and dependencies, circuit utilization and application performance can be poor [14].These three trends taken together – software-defined networking, dynamically reconfigurable optical circuits, and structured big data applications – motivate us to explore the design of an SDN controller using a “cross-layer” approach that configures the network based on big data application dynamics at run-time. In this paper, we focus on Hadoop as an example to explore the design of an integrated network control plane, and describe Hadoop job scheduling strategies to accommodate dynamic network configuration. We introduce the topology construction and routing mechanisms for a number of communication patterns, including single aggregation, data shuffling, and partially overlapping aggregation traffic patterns to improve application performance.The proposed topology configuration algorithms can be implemented using a small number of OpenFlow rules on each switch. Our preliminary estimation suggests that the flow rule installation introduces low overhead compared to the relatively long duration of MapReduce jobs. However, a number of challenges remain which have implications for SDN controller architectures. For example, in contrast to common SDN use cases such as WAN traffic engineering [12] and cloud network provisioning [8], run-time network configuration for big data jobs requires more rapid and frequentflow table updates. This imposes significant requirements on the scalability of the SDN controller and how fast it can update state across the network. Another challenge is in maintaining consistent network-wide routing updates with low latency, and in coordinating network reconfiguration requests from different applications in multi-tenancy environments.This is a work-in-progress, and there is clearly more work to be done to realize and fully evaluate the design. Nevertheless, we believe that this work shows early promise for achieving one of the oft-cited goals of software-define networking, that is to tightly integrate applications with the network to improve performance and utilization.

\section{INTEGRATED NETWORK CONTROL ARCHITECTURE}In this section, we describe the overall architecture of cross-layer network control for big data applications.\subsection{System Architecture}Figure 1 shows the system architecture of a cross-layer network control plane. We assume a hybrid electrical and optical data center network where OpenFlow-enabled top-of-rack (ToR) switches are connected to two aggregation networks, a multi-root tree with Ethernet switches and a MEMS-based optical circuit switch1. Each ToR switch has multiple optical uplinks connected to the optical switch (commodity switches typically have 4 to 6 uplinks). All the switches are controlled by a SDN controller which manages physical connectivity among ToR switches over optical circuits by configuring the optical switch. It can also manage the forwarding at ToR switches using OpenFlow rules.Many big data applications, such as Hadoop [1], Dryad [20], Spark [29] and HBase [2], have a master node, or application controller, that manages all incoming job requests. To support crosslayer network control, the SDN controller is interfaced to the master node for each individual application, such as the Hadoop scheduler or HBase master. It could also connect to broader coordination frameworks such as Mesos [13] that manage multiple co-existing applications sharing the data center.Since the SDN controller may be shared among multiple applications, it provides a general interface to configure devices and control forwarding in the network. It also provides a query interface to make authoritative network information available to applications. For big data applications, the SDN controller provides an interface that accepts traffic demand matrices from application controllers in a standard format. The traffic demand matrix describes the vol-ume and policy requirements for traffic exchanged between different source and destination racks.Using the network configuration interface, application controllers report traffic demands and structure from one or multiple jobs and issue a network configuration command to set up the topology accordingly. They can also use network information provided by the SDN controller, such as topology, to make more informed decisions on job scheduling and placement (further described in Section 3.2). Application controllers implement their own application-specific mechanisms to collect traffic demands from different components, and also define appropriate criteria to correlate and aggregate demands from multiple jobs.

\subsection{Traffic Pattern of Big Data Applications}
The traffic in big data applications consists of bulk transfer, data aggregation/partitioning, and latency sensitive control messages. The control traffic is typically low data rate and can be handled easily by even a relatively slow Ethernet. In our architecture, control messages are always sent over the packet switched network using default routes that direct traffic over the Ethernet2.Data aggregation and partitioning, where data are partitioned or aggregated between one server and a large number of other servers, is a common traffic pattern. For example, in MapReduce, the intermediate results from all the mappers will be aggregated at a reducer for performing the reduce function. The shuffle phase of MapReduce is actually a combination of multiple data aggregation patterns between mappers and reducers. In parallel database systems, most operations require merging and splitting data from different tables. Data aggregation requires high bandwidth to exchange large volumes of data between a potentially large number of servers. In the typical case of oversubscribed data center networks, the data aggregation and shuffling patterns can easily become performance bottlenecks. Our cross-layer network controller is designed primarily to address the challenge of handling a mix of multiple aggregation and data shuffling tasks.

\subsection{The Advantage of Application Awareness}For big data applications, an application-aware network controller provides improved performance. By carefully allocating and scheduling high-bandwidth links via optical paths, job completion time can be reduced significantly. Data center operators also benefit from better utilization of the relatively limited set of high-bandwidth optical links.Current approaches for allocating optical circuits in data centers, such as c-Through [26], Helios [18] and OSA [15], rely on network level statistics to estimate the traffic demand matrix in the data center. While these designs show the potential to benefit applications, recent work has shown that without a true application-level view of traffic demands and dependencies, circuit utilization and application performance can be poor [14]. First, it is difficult to estimate real application traffic demand based only on readings of network level statistics. Without accurate information about application demand, optical circuits may be configured between the wrong locations, or circuit flapping may occur from repeated corrections. Second, blindly optimizing circuit throughput without considering application structure could cause blocking among interdependent applications and poor application performance.


\section{Evaluation}We evaluate the performance of Spark SQL on two dimensions: SQL query processing performance and Spark program performance. In particular, we demonstrate that Spark SQL’s extensible architecture not only enables a richer set of functionalities, but brings substantial performance improvements over previous Spark-based SQL engines. In addition, for Spark application developers, the DataFrame API can bring substantial speedups over the native Spark API while making Spark programs more concise and easier to understand. Finally, applications that combine relational and procedural queries run faster on the integrated Spark SQL engine than by running SQL and procedural code as separate parallel jobs.
\subsection{SQL Performance}
We compared the performance of Spark SQL against Shark and Impala [23] using the AMPLab big data benchmark [3], which uses a web analytics workload developed by Pavlo et al. [31]. The benchmark contains four types of queries with different parameters performing scans, aggregation, joins and a UDF-based MapReduce job. We used a cluster of six EC2 i2.xlarge machines (one master, five workers) each with 4 cores, 30 GB memory and an 800 GB SSD, running HDFS 2.4, Spark 1.3, Shark 0.9.1 and Impala 2.1.1. The dataset was 110 GB of data after compression using the columnar Parquet format [5].Figure 8 shows the results for each query, grouping by the query type. Queries 1–3 have different parameters varying their selectivity, with 1a, 2a, etc being the most selective and 1c, 2c, etc being the least selective and processing more data. Query 4 uses a Pythonbased Hive UDF that was not directly supported in Impala, but was largely bound by the CPU cost of the UDF.We see that in all queries, Spark SQL is substantially faster than Shark and generally competitive with Impala. The main reason for the difference with Shark is code generation in Catalyst (Section 4.3.4), which reduces CPU overhead. This feature makes Spark SQL competitive with the C++ and LLVM based Impala engine in many of these queries. The largest gap from Impala is in query 3a where Impala chooses a better join plan because the selectivity of the queries makes one of the tables very small.

\subsection{DataFrames vs. Native Spark Code}

In addition to running SQL queries, Spark SQL can also help nonSQL developers write simpler and more efficient Spark code through the DataFrame API. Catalyst can perform optimizations on DataFrame operations that are hard to do with hand written code, such as predicate pushdown, pipelining, and automatic join selection. Even without these optimizations, the DataFrame API can result in more efficient execution due to code generation. This is especially true for Python applications, as Python is typically slower than the JVM.For this evaluation, we compared two implementations of a Spark program that does a distributed aggregation. The dataset consists of 1 billion integer pairs, (a, b) with 100,000 distinct values of a, on the same five-worker i2.xlarge cluster as in the previous section. We measure the time taken to compute the average of b for each value of a. First, we look at a version that computes the average using the map and reduce functions in the Python API for Spark:\noindent
\begin{verbatim}sum_and_count = \  data.map(lambda x: (x.a, (x.b, 1))) \     .reduceByKey(lambda x, y: (x[0]+y[0], x[1]+y[1])) \     .collect()[(x[0], x[1][0] / x[1][1]) for x in sum_and_count]
\end{verbatim}
In contrast, the same program can written as a simple manipulation using the DataFrame API:

\noindent
\begin{verbatim}df.groupBy("a").avg("b")
\end{verbatim}
Figure 9, shows that the DataFrame version of the code outperforms the hand written Python version by 12⇥, in addition to being much more concise. This is because in the DataFrame API, only the logical plan is constructed in Python, and all physical execution is compiled down into native Spark code as JVM bytecode, resulting in more efficient execution. In fact, the DataFrame version also outperforms a Scala version of the Spark code above by 2X. This is mainly due to code generation: the code in the DataFrame version avoids expensive allocation of key-value pairs that occurs in hand-written Scala code.

\subsection{Pipeline Performance}
The DataFrame API can also improve performance in applications that combine relational and procedural processing, by letting developers write all operations in a single program and pipelining computation across relational and procedural code. As a simple example, we consider a two-stage pipeline that selects a subset of text messages from a corpus and computes the most frequent words. Although very simple, this can model some real-world pipelines, e.g., computing the most popular words used in tweets by a specific demographic.

In this experiment, we generated a synthetic dataset of 10 billion messages in HDFS. Each message contained on average 10 words drawn from an English dictionary. The first stage of the pipeline uses a relational filter to select roughly 90\% of the messages. The second stage computes the word count.
First, we implemented the pipeline using a separate SQL query followed by a Scala-based Spark job, as might occur in environments that run separate relational and procedural engines (e.g., Hive and Spark). We then implemented a combined pipeline using the DataFrame API, i.e., using DataFrame’s relational operators to perform the filter, and using the RDD API to perform a word count on the result. Compared with the first pipeline, the second pipeline avoids the cost of saving the whole result of the SQL query to an HDFS file as an intermediate dataset before passing it into the Spark job, because SparkSQL pipelines the map for the word count with the relational operators for the filtering. Figure 10 compares the runtime performance of the two approaches. In addition to being easier to understand and operate, the DataFrame-based pipeline also improves performance by 2X.

\section{Related Work}
\textbf{Programming Model} Several systems have sought to combine relational processing with the procedural processing engines initially used for large clusters. Of these, Shark [38] is the closest to Spark SQL, running on the same engine and offering the same combination of relational queries and advanced analytics. Spark SQL improves on Shark through a richer and more programmer-friendly API, DataFrames, where queries can be combined in a modularway using constructs in the host programming language (see Section 3.4). It also allows running relational queries directly on native RDDs, and supports a wide range of data sources beyond Hive.
One system that inspired Spark SQL’s design was DryadLINQ [20], which compiles language-integrated queries in C\# to a distributed DAG execution engine. LINQ queries are also relational but can operate directly on C\# objects. Spark SQL goes beyond DryadLINQ by also providing a DataFrame interface similar to common data science libraries [32, 30], an API for data sources and types, and support for iterative algorithms through execution on Spark.
Other systems use only a relational data model internally and relegate procedural code to UDFs. For example, Hive and Pig [36, 29] offer relational query languages but have widely used UDF interfaces. ASTERIX [8] has a semi-structured data model internally. Stratosphere [2] also has a semi-structured model, but offers APIs in Scala and Java that let users easily call UDFs. PIQL [7] likewise provides a Scala DSL. Compared to these systems, Spark SQL integrates more closely with native Spark applications by being able to directly query data in user-defined classes (native Java/Python objects), and lets developers mix procedural and relational APIs in the same language. In addition, through the Catalyst optimizer, Spark SQL implements both optimizations (e.g., code generation) and other functionality (e.g., schema inference for JSON and machine learning data types) that are not present in most large-scale computing frameworks. We believe that these features are essential to offering an integrated, easy-to-use environment for big data.
Finally, data frame APIs have been built both for single machines [32, 30] and clusters [13, 10]. Unlike previous APIs, Spark SQL optimizes DataFrame computations with a relational optimizer.
\textbf{Extensible Optimizers} The Catalyst optimizer shares similar goals with extensible optimizer frameworks such as EXODUS [17] and Cascades [16]. Traditionally, however, optimizer frameworks have required a domain-specific language to write rules in, as well as an “optimizer compiler” to translate them to runnable code. Our major improvement here is to build our optimizer using standard features of a functional programming language, which provide the same (and often greater) expressivity while decreasing the maintenance burden and learning curve. Advanced language features helped with many areas of Catalyst—for example, our approach to code generation using quasiquotes (Section 4.3.4) is one of the simplest and most composable approaches to this task that we know. While extensibility is hard to measure quantitatively, one promising indication is that Spark SQL had over 50 external contributors in the first 8 months after its release.
For code generation, LegoBase [22] recently proposed an approach using generative programming in Scala, which would be possible to use instead of quasiquotes in Catalyst.
\textbf{Advanced Analytics} Spark SQL builds on recent work to run advanced analytics algorithms on large clusters, including platforms for iterative algorithms [39] and graph analytics [15, 24]. The desire to expose analytics functions is also shared with MADlib [12], though the approach there is different, as MADlib had to use the limited interface of Postgres UDFs, while Spark SQL’s UDFs can be full-fledged Spark programs. Finally, techniques including Sinew and Invisible Loading [35, 1] have sought to provide and optimize queries over semi-structured data such as JSON. We hope to apply some of these techniques in our JSON data source.

\section{Conclusion}We have presented Spark SQL, a new module in Apache Spark providing rich integration with relational processing. Spark SQL extends Spark with a declarative DataFrame API to allow relational processing, offering benefits such as automatic optimization, and letting users write complex pipelines that mix relational and complex analytics. It supports a wide range of features tailored to large-scale data analysis, including semi-structured data, query federation, and data types for machine learning. To enable these features, Spark SQL is based on an extensible optimizer called Catalyst that makes it easy to add optimization rules, data sources and data types by embedding into the Scala programming language. User feedback and benchmarks show that Spark SQL makes it significantly simpler and more efficient to write data pipelines that mix relational and procedural processing, while offering substantial speedups over previous SQL-on-Spark engines.Spark SQL is open source at \url{http://spark.apache.org}.

\section{Acknowledgments}
We would like to thank Cheng Hao, Tayuka Ueshin, Tor Myklebust, Daoyuan Wang, and the rest of the Spark SQL contributors so far. We would also like to thank John Cieslewicz and the other members of the F1 team at Google for early discussions on the Catalyst optimizer. The work of authors Franklin and Kaftan was supported in part by: NSF CISE Expeditions Award CCF-1139158, LBNL Award 7076018, and DARPA XData Award FA8750-12-2-0331, and gifts from Amazon Web Services, Google, SAP, The Thomas and Stacey Siebel Foundation, Adatao, Adobe, Apple, Inc., Blue Goji, Bosch, C3Energy, Cisco, Cray, Cloudera, EMC2, Ericsson, Facebook, Guavus, Huawei, Informatica, Intel, Microsoft, NetApp, Pivotal, Samsung, Schlumberger, Splunk, Virdata and VMware.

\end{document}



